{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "普通方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0106], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1,2,3]).float()\n",
    "A=torch.nn.Linear(3, 5)._parameters['weight']\n",
    "B=torch.nn.Linear(5, 5)._parameters['weight']\n",
    "C=torch.nn.Linear(5, 1)._parameters['weight']\n",
    "\n",
    "x.matmul(A.T).matmul(B.T).matmul(C.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "权重运算符重载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetMat():\n",
    "    def __init__(self,Weight=None,Moudle=None):\n",
    "        if Weight !=None:\n",
    "            self.weight=Weight\n",
    "        elif Moudle !=None:\n",
    "            self.weight=Moudle._parameters['weight'].T\n",
    "        else:\n",
    "            raise Exception('No Weight or Moudle')\n",
    "        \n",
    "    def __mul__(self, other):\n",
    "        res = self.weight.matmul(other.weight)\n",
    "        return NetMat(Weight=res)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'NetMat(Weight={self.weight})'\n",
    "\n",
    "x = torch.tensor([1,2,3]).float()\n",
    "A=NetMat(Moudle=torch.nn.Linear(3, 5))\n",
    "B=NetMat(Moudle=torch.nn.Linear(5, 5))\n",
    "C=NetMat(Moudle=torch.nn.Linear(5, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetMat(Weight=tensor([[-0.0668],\n",
       "        [ 0.0700],\n",
       "        [ 0.0368]], grad_fn=<MmBackward0>))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A*B*C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1836], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.matmul((A*B*C).weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络运算符重载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoNet(\n",
       "  (Net): Sequential(\n",
       "    (0): MoNet(\n",
       "      (Net): Linear(in_features=10, out_features=1, bias=True)\n",
       "    )\n",
       "    (1): MoNet(\n",
       "      (Net): Linear(in_features=10, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MoNet import *\n",
    "layer()*layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cell(\n",
       "  (Net): Sequential(\n",
       "    (0:fc): Linear(in_features=10, out_features=1, bias=True)\n",
       "    (1:bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2:act): PReLU(num_parameters=1)\n",
       "    (3:dp): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoNet(\n",
      "  (Net): Sequential(\n",
      "    (0): MoNet(\n",
      "      (Net): Sequential(\n",
      "        (0): Layer(\n",
      "          (Net): Linear(in_features=1, out_features=10, bias=True)\n",
      "        )\n",
      "        (1): Cell(\n",
      "          (Net): Sequential(\n",
      "            (0:fc): Linear(in_features=10, out_features=10, bias=True)\n",
      "            (1:bn): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2:act): PReLU(num_parameters=1)\n",
      "            (3:dp): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Layer(\n",
      "      (Net): Linear(in_features=10, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2049],\n",
       "        [-0.3159]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from MoNet.monet import Cell, Layer\n",
    "\n",
    "F=Layer(1,10)*Cell(10,10)*Layer(10,1)\n",
    "print(F)\n",
    "F(torch.tensor([[0.0],\n",
    "                [1.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mix(\n",
       "  (Net): Sequential(\n",
       "    (0:input): Sequential(\n",
       "      (cell-0): Sequential(\n",
       "        (0:dp): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1:hiddens): Sequential(\n",
       "      (cell-0): Sequential(\n",
       "        (0:fc): Linear(in_features=10, out_features=32, bias=True)\n",
       "        (1:bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2:act): PReLU(num_parameters=1)\n",
       "        (3:dp): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (cell-1): Sequential(\n",
       "        (0:fc): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (1:bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2:act): PReLU(num_parameters=1)\n",
       "        (3:dp): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2:out): Sequential(\n",
       "      (cell-0): Sequential(\n",
       "        (0:fc): Linear(in_features=32, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MoNet.monet import Mix\n",
    "\n",
    "Mix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fc=Cell(1,5,['fc','act'])\n",
    "Hid1=Cell(5,1,['fc','act'])\n",
    "Hid2=Cell(5,1,['fc','act'])\n",
    "Out = Layer(2,1,'fc')\n",
    "\n",
    "x=torch.tensor([0.0])\n",
    "F1=(Fc*Hid1+Fc*Hid2)*Out\n",
    "F2=Fc*(Hid1+Hid2)*Out\n",
    "F1(x)==F2(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
